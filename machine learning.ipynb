{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.预测结果判断  \n",
    "过拟合：部分噪音过分影响了模型  \n",
    "欠拟合：机器学习模型选择有问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.偏差与方差\n",
    "Bias=E $\\widehat{f(x)}$-$\\ f(x)$  \n",
    "偏差衡量的是预测值与真实值的平均偏离程度：   \n",
    "Var=E[$\\widehat{f(x)}$-E $\\widehat{f(x)}$]<sup>2</sup>  \n",
    "方差衡量模型的稳定性  \n",
    "**过拟合**：低偏差、高方差  \n",
    "**欠拟合**：高偏差、低方差  \n",
    "存在最优模型复杂程度（用**均方误差**度量）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.正则化  \n",
    "OLS对训练数据进行过度拟合，可对其回归参数进行惩罚，思路即为**正则化**(Regularization)  \n",
    "**Ridge回归**：$\\Sigma$(y<sub>i</sub>-X<sub>i</sub><sup>T</sup>$\\beta$)<sup>2</sup>+$\\lambda\\Sigma\\beta$<sub>i</sub><sup>2</sup>  \n",
    "**Lasso回归**：$\\Sigma$(y<sub>i</sub>-X<sub>i</sub><sup>T</sup>$\\beta$)<sup>2</sup>+$\\lambda\\Sigma$|$\\beta$<sub>i</sub>|  \n",
    "梯度下降求损失最小\n",
    "牺牲无偏性，提高泛化能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.集成算法\n",
    "原始数据集通过随机采样，形成多个训练样本，分别进行分类训练，各弱分类器通过投票得出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.深度学习\n",
    "通过多层嵌套，叠加非线性映射"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
